print(t_test4_jw1_jw2)
t_test4_dpll_jw1 = t.test(df4[df4$heuristic == 'h2',]$number_of_backtracks  ,df4[df4$heuristic == 'jw_one_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test4_dpll_jw1)
t_test4_dpll_jw2 = t.test(df4[df4$heuristic == 'h2',]$number_of_backtracks  ,df4[df4$heuristic == 'jw_two_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test4_dpll_jw2)
t_test4_jw1_jw2 = t.test(df4[df4$heuristic == 'jw_one_sided',]$number_of_backtracks, df4[df4$heuristic == 'jw_two_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test4_jw1_jw2)
df9 = read.csv("C:/Users/Domantas/Desktop/VU AI/knowledge representation/sat_solver/sudoku9x9_results_expirement2.csv")
df9$heuristic <- as.factor(df9$heuristic)
unique(df9$heuristic)
t_test9_dpll_jw1 = t.test(df9[df9$heuristic == 'h2',]$number_of_backtracks  ,df9[df9$heuristic == 'jw_one_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_dpll_jw1)
t_test9_dpll_jw2 = t.test(df9[df9$heuristic == 'h2',]$number_of_backtracks  ,df9[df9$heuristic == 'jw_two_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_dpll_jw2)
t_test9_jw1_jw2 = t.test(df9[df9$heuristic == 'jw_one_sided',]$number_of_backtracks, df4[df4$heuristic == 'jw_two_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_jw1_jw2)
t_test9_dpll_jw2 = t.test(df9[df9$heuristic == 'jw_two_sided',]$number_of_backtracks, df9[df9$heuristic == 'h2',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_dpll_jw2)
t_test9_dpll_jw1 = t.test(df9[df9$heuristic == 'h2',]$number_of_backtracks  ,df9[df9$heuristic == 'jw_one_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_dpll_jw1)
t_test9_dpll_jw2 = t.test(df9[df9$heuristic == 'jw_two_sided',]$number_of_backtracks, df9[df9$heuristic == 'h2',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_dpll_jw2)
t_test9_jw1_jw2 = t.test(df9[df9$heuristic == 'jw_one_sided',]$number_of_backtracks, df4[df4$heuristic == 'jw_two_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_jw1_jw2)
t_test4_dpll_jw1 = t.test(df4[df4$heuristic == 'h2',]$number_of_backtracks  ,df4[df4$heuristic == 'jw_one_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test4_dpll_jw1)
t_test4_dpll_jw2 = t.test(df4[df4$heuristic == 'h2',]$number_of_backtracks  ,df4[df4$heuristic == 'jw_two_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test4_dpll_jw2)
t_test4_jw1_jw2 = t.test(df4[df4$heuristic == 'jw_one_sided',]$number_of_backtracks, df4[df4$heuristic == 'jw_two_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test4_jw1_jw2)
t_test9_dpll_jw1 = t.test(df9[df9$heuristic == 'h2',]$number_of_backtracks  ,df9[df9$heuristic == 'jw_one_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_dpll_jw1)
t_test9_dpll_jw2 = t.test(df9[df9$heuristic == 'jw_two_sided',]$number_of_backtracks, df9[df9$heuristic == 'h2',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_dpll_jw2)
t_test9_jw1_jw2 = t.test(df9[df9$heuristic == 'jw_one_sided',]$number_of_backtracks, df4[df4$heuristic == 'jw_two_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_jw1_jw2)
df9 = read.csv("C:/Users/Domantas/Desktop/VU AI/knowledge representation/sat_solver/sudoku9x9_results_expirement2.csv")
df9$heuristic <- as.factor(df9$heuristic)
unique(df9$heuristic)
t_test9_dpll_jw1 = t.test(df9[df9$heuristic == 'h2',]$number_of_backtracks  ,df9[df9$heuristic == 'jw_one_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_dpll_jw1)
t_test9_dpll_jw2 = t.test(df9[df9$heuristic == 'jw_two_sided',]$number_of_backtracks, df9[df9$heuristic == 'h2',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_dpll_jw2)
t_test9_jw1_jw2 = t.test(df9[df9$heuristic == 'jw_one_sided',]$number_of_backtracks, df4[df4$heuristic == 'jw_two_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_jw1_jw2)
View(df9)
str(df9)
summary(df9)
df9 = read.csv("C:/Users/Domantas/Desktop/VU AI/knowledge representation/sat_solver/sudoku9x9_results_expirement2.csv")
df9$heuristic <- as.factor(df9$heuristic)
unique(df9$heuristic)
t_test9_dpll_jw1 = t.test(df9[df9$heuristic == 'h2',]$number_of_backtracks  ,df9[df9$heuristic == 'jw_one_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_dpll_jw1)
t_test9_dpll_jw2 = t.test(df9[df9$heuristic == 'jw_two_sided',]$number_of_backtracks, df9[df9$heuristic == 'h2',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_dpll_jw2)
t_test9_jw1_jw2 = t.test(df9[df9$heuristic == 'jw_one_sided',]$number_of_backtracks, df9[df9$heuristic == 'jw_two_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_jw1_jw2)
t_test9_dpll_jw1 = t.test(df9[df9$heuristic == 'h2',]$number_of_backtracks  ,df9[df9$heuristic == 'jw_one_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_dpll_jw1)
t_test9_dpll_jw2 = t.test(df9[df9$heuristic == 'jw_two_sided',]$number_of_backtracks, df9[df9$heuristic == 'h2',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_dpll_jw2)
t_test9_jw1_jw2 = t.test(df9[df9$heuristic == 'jw_two_sided',]$number_of_backtracks, df9[df9$heuristic == 'jw_one_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test9_jw1_jw2)
t_test4_dpll_jw1 = t.test(df4[df4$heuristic == 'h2',]$number_of_backtracks  ,df4[df4$heuristic == 'jw_one_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test4_dpll_jw1)
t_test4_dpll_jw2 = t.test(df4[df4$heuristic == 'h2',]$number_of_backtracks  ,df4[df4$heuristic == 'jw_two_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test4_dpll_jw2)
t_test4_jw1_jw2 = t.test(df4[df4$heuristic == 'jw_one_sided',]$number_of_backtracks, df4[df4$heuristic == 'jw_two_sided',]$number_of_backtracks, alternative = 'greater' )
print(t_test4_jw1_jw2)
df = readxl::read_xlsx('C:/Users/Domantas/Desktop/data-sample-SIR-stats-lecture.xlsx')
View(df)
t.test(x=df[df$condition == 'control']$score, y=df[df$condition == 'cdt1']$score)
t.test(x=df[df$condition == 'control',]$score, y=df[df$condition == 'cdt1',]$score)
sd(df[df$condition == 'control',]$score)
sd(df[df$condition == 'cdt1',]$score)
var(df[df$condition == 'control',]$score)
var(df[df$condition == 'cdt1',]$score)
t.test(x=df[df$condition == 'control',]$score, y=df[df$condition == 'cdt1',]$score)
library(readxl)
df = read_xlsx("C:/Users/Domantas/Desktop/Evaluation form experiment Robot interaction (Antwoorden).xlsx") Evaluation form experiment Robot interaction (Antwoorden).xlsx
df = read_xlsx("C:/Users/Domantas/Desktop/Evaluation form experiment Robot interaction (Antwoorden).xlsx")
View(df)
install.packages("foreign", dependencies=TRUE)
install.packages("lavaan", dependencies=TRUE)
colnames(df)
print(colnames(df))
df[, grepl( "Likeable" , names(df))]
names(df[, grepl( "Likeable" , names(df))])
names(df[, grepl( "Warm" , names(df))])
names(df[, grepl( "Trustworthy" , names(df))])
names(df[, grepl( "Friendly" , names(df))])
#soiability
names(df[, grepl( "Likeable" , names(df))])
names(df[, grepl( "Warm" , names(df))])
names(df[, grepl( "Trustworthy" , names(df))])
names(df[, grepl( "Friendly" , names(df))])
#animacy
names(df[, grepl( "Alive" , names(df))])
names(df[, grepl( "Natural" , names(df))])
names(df[, grepl( "Real" , names(df))])
names(df[, grepl( "Human-like" , names(df))])
#Agency
names(df[, grepl( "Self-reliant" , names(df))])
names(df[, grepl( "Rational" , names(df))])
names(df[, grepl( "Intentional" , names(df))])
names(df[, grepl( "Intelligent" , names(df))])
#Disturbance
names(df[, grepl( "Creepy" , names(df))])
names(df[, grepl( "Scary" , names(df))])
names(df[, grepl( "Uncanny" , names(df))])
names(df[, grepl( "Weird" , names(df))])
library(dplyr)
print(colnames(df))
df %>% group_by(`Which group were you in?`)
View(df %>% group_by(`Which group were you in?`))
df = read_xlsx("C:/Users/Domantas/Desktop/Evaluation form experiment Robot interaction (Antwoorden).xlsx")
library(lavaan)
library(foreign)
group1_df = read_xlsx("C:/Users/Domantas/Desktop/VU AI/socially intelligent robotics/TA-group-18/CFA/group1.xlsx")
View(group1_df)
df == group1_df
group1_df = read_xlsx("C:/Users/Domantas/Desktop/VU AI/socially intelligent robotics/TA-group-18/CFA/group1.xlsx")
group2_df = read_xlsx("C:/Users/Domantas/Desktop/VU AI/socially intelligent robotics/TA-group-18/CFA/group2.xlsx")
View(group2_df)
HS.model <- ' visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed   =~ x7 + x8 + x9 '
#group1 get names according factors:
#soiability
names(group1_df[, grepl( "Likeable" , names(group1_df))])
names(group1_df[, grepl( "Warm" , names(group1_df))])
names(group1_df[, grepl( "Trustworthy" , names(group1_df))])
names(group1_df[, grepl( "Friendly" , names(group1_df))])
#animacy
names(group1_df[, grepl( "Alive" , names(group1_df))])
names(group1_df[, grepl( "Natural" , names(group1_df))])
names(group1_df[, grepl( "Real" , names(group1_df))])
names(group1_df[, grepl( "Human-like" , names(group1_df))])
#Agency
names(group1_df[, grepl( "Self-reliant" , names(group1_df))])
names(group1_df[, grepl( "Rational" , names(group1_df))])
names(group1_df[, grepl( "Intentional" , names(group1_df))])
names(group1_df[, grepl( "Intelligent" , names(group1_df))])
#Disturbance
names(group1_df[, grepl( "Creepy" , names(group1_df))])
names(group1_df[, grepl( "Scary" , names(group1_df))])
names(group1_df[, grepl( "Uncanny" , names(group1_df))])
names(group1_df[, grepl( "Weird" , names(df))])
names(group1_df[, grepl( "Likeable" , names(group1_df))])
names(group1_df[, grepl( "Warm" , names(group1_df))])
names(group1_df[, grepl( "Trustworthy" , names(group1_df))])
names(group1_df[, grepl( "Friendly" , names(group1_df))])
names(group1_df[, grepl( "Alive" , names(group1_df))])
names(group1_df[, grepl( "Natural" , names(group1_df))])
names(group1_df[, grepl( "Real" , names(group1_df))])
names(group1_df[, grepl( "Human-like" , names(group1_df))])
sociability = c("Likeable...16","Warm...18", "Trustworthy...24","Friendly...22")
names(group1_df[, grepl( "Alive" , names(group1_df))])
names(group1_df[, grepl( "Natural" , names(group1_df))])
names(group1_df[, grepl( "Real" , names(group1_df))])
names(group1_df[, grepl( "Human-like" , names(group1_df))])
animacy = c("Alive...20","Natural...26","Real...17","Human-like...25")
#Agency
names(group1_df[, grepl( "Self-reliant" , names(group1_df))])
names(group1_df[, grepl( "Rational" , names(group1_df))])
names(group1_df[, grepl( "Intentional" , names(group1_df))])
names(group1_df[, grepl( "Intelligent" , names(group1_df))])
agency = c("Self-reliant...27","Rational...29","Intentional...21","Intelligent...30")
#Disturbance
names(group1_df[, grepl( "Creepy" , names(group1_df))])
names(group1_df[, grepl( "Scary" , names(group1_df))])
names(group1_df[, grepl( "Uncanny" , names(group1_df))])
names(group1_df[, grepl( "Weird" , names(df))])
names(group1_df[, grepl( "Creepy" , names(group1_df))])
names(group1_df[, grepl( "Scary" , names(group1_df))])
names(group1_df[, grepl( "Uncanny" , names(group1_df))])
names(group1_df[, grepl( "Weird" , names(df))])
names(group1_df[, grepl( "Weird" , names(group1_df))])
#Disturbance
names(group1_df[, grepl( "Creepy" , names(group1_df))])
names(group1_df[, grepl( "Scary" , names(group1_df))])
names(group1_df[, grepl( "Uncanny" , names(group1_df))])
names(group1_df[, grepl( "Weird" , names(group1_df))])
data(HolzingerSwineford1939)
View(data(HolzingerSwineford1939))
HS.model <- ' sociability  =~ Alive...20 + Natural...26 + Real...17 + Human-like...25'
fit <- cfa(HS.model, data = group1_df)
HS.model <- 'sociability  =~ `Alive...20` + `Natural...26` + `Real...17` + `Human-like...25`'
fit <- cfa(HS.model, data = group1_df)
summarry(fit)
summarise(fit)
summary(fit, standardized=TRUE)
HS.model <- 'animacy  =~ `Alive...20` + `Natural...26` + `Real...17` + `Human-like...25`
soiability =~ `Likeable...16` + `Warm...18` + `Trustworthy...24` + `Friendly...22`
agency =~ `Self-reliant...27` + `Rational...29` + `Intentional...21` + `Intelligent...30`
disturbance =~ `Weird...28` +  `Scary...23` + `Uncanny...19` + `Weird...28`
'
fit <- cfa(HS.model, data = group1_df)
summary(fit, standardized=TRUE)
#group2 get names according factors:
names(group2_df[, grepl( "Likeable" , names(group2_df))])
names(group2_df[, grepl( "Warm" , names(group2_df))])
names(group2_df[, grepl( "Trustworthy" , names(group2_df))])
names(group2_df[, grepl( "Friendly" , names(group2_df))])
gr2.model <- 'animacy  =~ `Alive...20` + `Natural...26` + `Real...17` + `Human-like...25`
soiability =~ `Likeable...16` + `Warm...18` + `Trustworthy...24` + `Friendly...22`
agency =~ `Self-reliant...27` + `Rational...29` + `Intentional...21` + `Intelligent...30`
disturbance =~ `Weird...28` +  `Scary...23` + `Uncanny...19` + `Weird...28`
'
fit <- cfa(gr2.model, data = group2_df)
gr1.model <- 'animacy  =~ `Alive...20` + `Natural...26` + `Real...17` + `Human-like...25`
soiability =~ `Likeable...16` + `Warm...18` + `Trustworthy...24` + `Friendly...22`
agency =~ `Self-reliant...27` + `Rational...29` + `Intentional...21` + `Intelligent...30`
disturbance =~ `Weird...28` +  `Scary...23` + `Uncanny...19` + `Weird...28`
'
fit1 <- cfa(gr1.model, data = group1_df)
gr2.model <- 'animacy  =~ `Alive...20` + `Natural...26` + `Real...17` + `Human-like...25`
soiability =~ `Likeable...16` + `Warm...18` + `Trustworthy...24` + `Friendly...22`
agency =~ `Self-reliant...27` + `Rational...29` + `Intentional...21` + `Intelligent...30`
disturbance =~ `Weird...28` +  `Scary...23` + `Uncanny...19` + `Weird...28`
'
fit2 <- cfa(gr2.model, data = group2_df)
summary(fit1, standardized=TRUE)
summary(fit2, standardized=TRUE)
summary(fit, standardized=TRUE)
summary(fit1, standardized=TRUE)
fit1 <- cfa(gr1.model, data = group1_df)
summary(fit1, standardized=TRUE)
gr1.model <- 'animacy  =~ `Alive...20` + `Natural...26` + `Real...17` + `Human-like...25`
soiability =~ `Likeable...16` + `Warm...18` + `Trustworthy...24` + `Friendly...22`
agency =~ `Self-reliant...27` + `Rational...29` + `Intentional...21` + `Intelligent...30`
disturbance =~ `Weird...28` +  `Scary...23` + `Uncanny...19` + `Weird...28`
'
fit1 <- cfa(gr1.model, data = group1_df)
HS.model <- 'animacy  =~ `Alive...20` + `Natural...26` + `Real...17` + `Human-like...25`
soiability =~ `Likeable...16` + `Warm...18` + `Trustworthy...24` + `Friendly...22`
agency =~ `Self-reliant...27` + `Rational...29` + `Intentional...21` + `Intelligent...30`
disturbance =~ `Weird...28` +  `Scary...23` + `Uncanny...19` + `Weird...28`
'
fit1 <- cfa(HS.model, data = group1_df)
summary(fit1, standardized=TRUE)
HS.model <- 'animacy  =~ `Alive...20` + `Natural...26` + `Real...17` + `Human-like...25`
soiability =~ `Likeable...16` + `Warm...18` + `Trustworthy...24` + `Friendly...22`
agency =~ `Self-reliant...27` + `Rational...29` + `Intentional...21` + `Intelligent...30`
disturbance =~ `Weird...28` +  `Scary...23` + `Uncanny...19` + `Weird...28`
'
fit1 <- cfa(HS.model, data = group1_df)
summary(fit1, standardized=TRUE)
HS.model <- 'animacy  =~ `Alive...20` + `Natural...26` + `Real...17` + `Human-like...25`
soiability =~ `Likeable...16` + `Warm...18` + `Trustworthy...24` + `Friendly...22`
agency =~ `Self-reliant...27` + `Rational...29` + `Intentional...21` + `Intelligent...30`
disturbance =~ `Weird...28` +  `Scary...23` + `Uncanny...19` + `Weird...28`
'
fit <- cfa(HS.model, data = group1_df)
summary(fit, standardized=TRUE)
fit_first <- cfa(HS.model, data = group1_df)
summary(fit_first, standardized=TRUE)
HS.model <- 'animacy  =~ `Alive...20` + `Natural...26` + `Real...17` + `Human-like...25`
soiability =~ `Likeable...16` + `Warm...18` + `Trustworthy...24` + `Friendly...22`
agency =~ `Self-reliant...27` + `Rational...29` + `Intentional...21` + `Intelligent...30`
disturbance =~ `Weird...28` +  `Scary...23` + `Uncanny...19` + `Weird...28`'
fit2 <- cfa(HS.model, data = group1_df)
group1_df = read_xlsx("C:/Users/Domantas/Desktop/VU AI/socially intelligent robotics/TA-group-18/CFA/group1.xlsx")
group2_df = read_xlsx("C:/Users/Domantas/Desktop/VU AI/socially intelligent robotics/TA-group-18/CFA/group2.xlsx")
#group1 get names according factors:
#soiability
names(group1_df[, grepl( "Likeable" , names(group1_df))])
names(group1_df[, grepl( "Warm" , names(group1_df))])
names(group1_df[, grepl( "Trustworthy" , names(group1_df))])
names(group1_df[, grepl( "Friendly" , names(group1_df))])
sociability = c("Likeable...16","Warm...18", "Trustworthy...24","Friendly...22")
#animacy
names(group1_df[, grepl( "Alive" , names(group1_df))])
names(group1_df[, grepl( "Natural" , names(group1_df))])
names(group1_df[, grepl( "Real" , names(group1_df))])
names(group1_df[, grepl( "Human-like" , names(group1_df))])
animacy = c("Alive...20","Natural...26","Real...17","Human-like...25")
#Agency
names(group1_df[, grepl( "Self-reliant" , names(group1_df))])
names(group1_df[, grepl( "Rational" , names(group1_df))])
names(group1_df[, grepl( "Intentional" , names(group1_df))])
names(group1_df[, grepl( "Intelligent" , names(group1_df))])
agency = c("Self-reliant...27","Rational...29","Intentional...21","Intelligent...30")
#Disturbance
names(group1_df[, grepl( "Creepy" , names(group1_df))])
names(group1_df[, grepl( "Scary" , names(group1_df))])
names(group1_df[, grepl( "Uncanny" , names(group1_df))])
names(group1_df[, grepl( "Weird" , names(group1_df))])
disturbance = c("Weird...28","Scary...23","Uncanny...19","Weird...28")
HS.model <- 'animacy  =~ `Alive...20` + `Natural...26` + `Real...17` + `Human-like...25`
soiability =~ `Likeable...16` + `Warm...18` + `Trustworthy...24` + `Friendly...22`
agency =~ `Self-reliant...27` + `Rational...29` + `Intentional...21` + `Intelligent...30`
disturbance =~ `Weird...28` +  `Scary...23` + `Uncanny...19` + `Weird...28`'
fit2 <- cfa(HS.model, data = group1_df)
summary(fit, standardized=TRUE)
cfa(HS.model, data = group1_df)
lavaan::
df = read_xlsx("C:/Users/Domantas/Desktop/VU AI/socially intelligent robotics/TA-group-18/CFA/Evaluation form experiment Robot interaction (Antwoorden).xlsx")
names(df)
HS.model <- 'animacy  =~ `Alive...20` + `Natural...26` + `Real...17` + `Human-like...25`
soiability =~ `Likeable...16` + `Warm...18` + `Trustworthy...24` + `Friendly...22`
agency =~ `Self-reliant...27` + `Rational...29` + `Intentional...21` + `Intelligent...30`
disturbance =~ `Weird...28` +  `Scary...23` + `Uncanny...19` + `Weird...28`'
fit <- cfa(HS.model, data = df, group = `Which group were you in?`)
fit <- cfa(HS.model, data = df, group = `"Which group were you in?"`)
fit <- cfa(HS.model, data = df, group = "Which group were you in?")
read.csv('C:/Users/Domantas/Desktop/VU AI/EDDA/assignment 1/birthweight.txt')
df <- read.csv('C:/Users/Domantas/Desktop/VU AI/EDDA/assignment 1/birthweight.txt')
df
weights <- read.csv('C:/Users/Domantas/Desktop/VU AI/EDDA/assignment 1/birthweight.txt')
print(weights)
qqplot(weights)
qqplot(x= weights)
qqplot(y= weights)
View(weights)
qqplot(df$birthweight)
shapiro.test(df$birthweight)
qqnorm(df$birthweight)
qqnorm(df$birthweight)
qqplot(df$birthweight)
qqnorm(df$birthweight)
#bounded 96%-CI for mean of given birthweigts sample
n = length(df)
n
#bounded 96%-CI for mean of given birthweigts sample
n = nrow(df)
mu = mean(df$birthweight)
s = var(df$birthweight)
s
sqrt(s)
range(df$birthweight)
print(range(df$birthweight))
sd(df$birthweight)
s = sqrt(variance)
variance = var(df$birthweight)
s = sqrt(variance)
s
sd(df$birthweight)
m = z_98p*s/sqrt(n)
z_98p = 2.05 # value from z score table for 98th percentile
m = z_98p*s/sqrt(n)
bounded_CI = c(mu - m, mu + m)
bounded_CI = c(mu - m, mu + m) #bounded 96% CI for mu
library(dplyr)
df <- read.csv('Data/birthweight.txt') # reading data
#normality check with Shapiro-wilk test and qqpplot
shapiro.test(df$birthweight)
qqnorm(df$birthweight)
#bounded 96%-CI for mean of given birthweights sample
#EXAMPLE (continued) An (asymptotic) 95%-confidence interval for µ is the interval [X¯ − m, X¯ + m], where m = 1.96s/√n
n = nrow(df)
mu = mean(df$birthweight)
variance = var(df$birthweight)
s = sd(df$birthweight)
z_98p = 2.05 # value from z score table for 98th percentile
m = z_98p*s/sqrt(n) #m = 1.96s/√n
bounded_CI = c(mu - m, mu + m) #bounded 96% CI for mu
bounded_CI
# calculating sample size for 100 length CI
get_m <- function(n) {
s = sd(df$birthweight)
z_98p = 2.05 # value from z score table for 98th percentile
m = z_98p*s/sqrt(n)
return(m)
}
for (sample_size in 1:1000) {
lower_bound = mu - get_m(sample_size)
upper_bound = mu + get_m(sample_size)
CI_length <- upper_bound - lower_bound
if (CI_length <= 100) {
break
}
}
sample_size
CI_length
# bootstrap 96%-CI:
B = 1000
Tstar = 1:B
for (i in 1:B){
Xstar = sample(df$birthweight, replace=TRUE)
Tstar[i] = mean(Xstar)
}
Tstar20 = quantile(Tstar, 0.020)
Tstar980 = quantile(Tstar, 0.980)
sum(Tstar<Tstar20)
bootstrap_CI = c(2*mu-Tstar980,2*mu-Tstar20)
bootstrap_CI
# h0 mean <= 2800
t.test(df$birthweight, mu=2800, alt="g")
# p value 0.01357 means that h0 has to be rejected in favor of h1
# which means that true mean is greater than 2800
# sign test
birtweight_results = df[,1]; birtweight_results
num_of_results_gt_than_2800 = sum(birtweight_results > 2800)
binom.test(num_of_results_gt_than_2800, length(birtweight_results))
library(dplyr)
df <- read.csv('Data/birthweight.txt') # reading data
#normality check with Shapiro-wilk test and qqpplot
shapiro.test(df$birthweight)
qqnorm(df$birthweight)
#bounded 96%-CI for mean of given birthweights sample
#EXAMPLE (continued) An (asymptotic) 95%-confidence interval for µ is the interval [X¯ − m, X¯ + m], where m = 1.96s/√n
n = nrow(df)
mu = mean(df$birthweight)
variance = var(df$birthweight)
s = sd(df$birthweight)
z_98p = 2.05 # value from z score table for 98th percentile
m = z_98p*s/sqrt(n) #m = 1.96s/√n
bounded_CI = c(mu - m, mu + m) #bounded 96% CI for mu
bounded_CI
# calculating sample size for 100 length CI
get_m <- function(n) {
s = sd(df$birthweight)
z_98p = 2.05 # value from z score table for 98th percentile
m = z_98p*s/sqrt(n)
return(m)
}
for (sample_size in 1:1000) {
lower_bound = mu - get_m(sample_size)
upper_bound = mu + get_m(sample_size)
CI_length <- upper_bound - lower_bound
if (CI_length <= 100) {
break
}
}
sample_size
CI_length
# bootstrap 96%-CI:
B = 1000
Tstar = 1:B
for (i in 1:B){
Xstar = sample(df$birthweight, replace=TRUE)
Tstar[i] = mean(Xstar)
}
Tstar20 = quantile(Tstar, 0.020)
Tstar980 = quantile(Tstar, 0.980)
sum(Tstar<Tstar20)
bootstrap_CI = c(2*mu-Tstar980,2*mu-Tstar20)
bootstrap_CI
# h0 mean <= 2800
t.test(df$birthweight, mu=2800, alt="g")
# p value 0.01357 means that h0 has to be rejected in favor of h1
# which means that true mean is greater than 2800
# sign test
birtweight_results = df[,1]; birtweight_results
num_of_results_gt_than_2800 = sum(birtweight_results > 2800)
binom.test(num_of_results_gt_than_2800, length(birtweight_results))
# probability of success 0.569
library(dplyr)
df <- read.csv('Data/birthweight.txt') # reading data
getwd
getwd()
setwd('C:\Users\Domantas\Desktop\VU AI\EDDA\EDDA_assignment1')
setwd('C:/Users/Domantas/Desktop/VU AI/EDDA/EDDA_assignment1')
getwd()
library(dplyr)
df <- read.csv('Data/birthweight.txt') # reading data
#normality check with Shapiro-wilk test and qqpplot
shapiro.test(df$birthweight)
qqnorm(df$birthweight)
#bounded 96%-CI for mean of given birthweights sample
#EXAMPLE (continued) An (asymptotic) 95%-confidence interval for µ is the interval [X¯ − m, X¯ + m], where m = 1.96s/√n
n = nrow(df)
mu = mean(df$birthweight)
variance = var(df$birthweight)
s = sd(df$birthweight)
z_98p = 2.05 # value from z score table for 98th percentile
m = z_98p*s/sqrt(n) #m = 1.96s/√n
bounded_CI = c(mu - m, mu + m) #bounded 96% CI for mu
bounded_CI
get_m <- function(n) {
s = sd(df$birthweight)
z_98p = 2.05 # value from z score table for 98th percentile
m = z_98p*s/sqrt(n)
return(m)
}
for (sample_size in 1:1000) {
lower_bound = mu - get_m(sample_size)
upper_bound = mu + get_m(sample_size)
CI_length <- upper_bound - lower_bound
if (CI_length <= 100) {
break
}
}
sample_size
CI_length
# bootstrap 96%-CI:
B = 1000
Tstar = 1:B
for (i in 1:B){
Xstar = sample(df$birthweight, replace=TRUE)
Tstar[i] = mean(Xstar)
}
Tstar20 = quantile(Tstar, 0.020)
Tstar980 = quantile(Tstar, 0.980)
sum(Tstar<Tstar20)
bootstrap_CI = c(2*mu-Tstar980,2*mu-Tstar20)
bootstrap_CI
# h0 mean <= 2800
t.test(df$birthweight, mu=2800, alt="g")
birtweight_results = df[,1]; birtweight_results
num_of_results_gt_than_2800 = sum(birtweight_results > 2800)
binom.test(num_of_results_gt_than_2800, length(birtweight_results))
birtweight_results = df[,1]; birtweight_results
num_of_results_gt_than_2800 = sum(birtweight_results > 2800)
binom.test(num_of_results_gt_than_2800, length(birtweight_results))
binom.test(num_of_results_gt_than_2800, length(birtweight_results), alt='g')
# h0 mean <= 2800
t.test(df$birthweight, mu=2800, alt="g")
birtweight_results
birtweight_results > 2800
sum(birtweight_results > 2800)
