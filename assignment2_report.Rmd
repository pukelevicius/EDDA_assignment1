---
title: "Group 2"
author:
  - Silver Lee-A-Fong
  - Jakub Lewkowicz
  - Domantas Pukeleviƒçius
date: "2023-03-02"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Exercise 1. Trees
#### a)
In treeVolume data set we can distinguish response variable "Volume" and explanatory variables such as "type", "height" and "diameter". We performed ANOVA with response variable "Volume" and only one explanatory variable "type" to analyse if type of a tree impacts its volume. Based on p-value from ANOVA table, we can observe that tree volume is not significantly impacted by a tree type.
```{r}
df <- read.csv("Data/treeVolume.txt",header = TRUE, sep = "")
df$type = as.factor(df$type)
anova_m = lm(volume ~ type, data=df);anova(anova_m)
```
We split data into tree categories and compared means of those two sample groups by performing t-test. Such t-test can be related to ANOVA performed above, because it also compares significant difference between volumes in those two groups. Summarizing t-test p-value implies that volume is not impacted by type of a tree.

```{r}
beech_samples = df[df$type == "beech", "volume"]
oak_samples = df[df$type == "oak", "volume"]
t.test(beech_samples, oak_samples)
```

Estimated volumes of those two tree types can be expressed as sample mean for a particular group and standard error.
\[\bar{X} = \frac{1}{n}\sum_{i=1}^{n}X_i\]
\[SE = \frac{\sigma}{\sqrt{n}}\]
```{r}
beech_mean = mean(beech_samples); oak_mean = mean(oak_samples)
se_beech = sd(beech_samples) / sqrt(length(beech_samples))
se_oak = sd(oak_samples) / sqrt(length(oak_samples))
beech_mean; se_beech
oak_mean; se_oak
```

#### b)

We performed ANOVA where we included both height and diameter as explanatory variables and volume as response variable. From ANOVA table we can observe that both factors have significant impact on tree's volume.

```{r}
anova_m = lm(volume ~ height + diameter, data=df); anova(anova_m)
```
We also performed different ANOVAs on groups separated by types. In this test we wanted to test influence of diameter and height separately on those two groups. From ANOVA tables where our explanatory variable was diameter, we can observe that volume is influenced in non significantly different way for both groups. Contrary, from ANOVA tables where height was explanatory variable, we can observe that it does not influence oak's volume in a significant way. Beech type tree's height influences it's volume in a significant way.
```{r}
anova_beech_diameter = lm(beech_samples ~ df[df$type == "beech", "diameter"]); anova(anova_beech_diameter)
anova_oak_diameter = lm(oak_samples ~ df[df$type == "oak", "diameter"]); anova(anova_oak_diameter)

anova_beech_height = lm(beech_samples ~ df[df$type == "beech", "height"]); anova(anova_beech_height)
anova_oak_height = lm(oak_samples ~ df[df$type == "oak", "height"]); anova(anova_oak_height)
```

#### c)

Based on previously achieved results we can draw following conclusions:
  - Type does not impact tree's volume.
  - If we take all samples into consideration both height and diameter impact tree's volume significantly.
  - If we analyse height and diameter influence on tree's volume grouped by tree's type, we can observe that height does not influence oak's volume in a significant way.
  
We can observe that height and diameter are correlated for beech type trees, while they are not for oak type trees. This observation can also explain why height does not impact oak's volume in a significant way (what we observed previously).
```{r}
par(mfrow=c(1, 2))
plot(df[df$type == "beech", "diameter"], df[df$type == "beech", "height"])
plot(df[df$type == "oak", "diameter"], df[df$type == "oak", "height"])
cor.test(df[df$type == "beech", "diameter"], df[df$type == "beech", "height"])
cor.test(df[df$type == "oak", "diameter"], df[df$type == "oak", "height"])
```
Using the resulting model we predicted volume of a tree, based on the avaregae diameter.
```{r}
avg_diameter = mean(df$diameter)
model = lm(volume ~ diameter, data=df);
predict(model, data.frame(diameter = c(avg_diameter)))
```

#### d)
We decided to compare two different linear models. In both volume is a response variable, both have height and diameter as explanatory variable. Second model additionaly includes interaction between diameter and height, because those factors might be dependent on each other, therefore we decided to test it. P-value from ANOVA table confirms that adding interaction (between diameter and height) to a model2, significantly improves its fit over model1.
```{r}
model1 = lm(volume ~ diameter + height, data=df)
model2 = lm(volume ~ diameter + height + diameter*height, data=df)
anova(model1, model2)
```

### Exercise 2. Expenditure on criminal activities

### a)
Influence points investigation was done by calculating Cook's distances for fitted with linear regression model where expend is response variable and bad, crime, lawyers, employ and pop are explanatory variables. It was found that data points at indexes 5, 8, 35 and 44 produce Cook's distance values larger than 1, which makes these indices influence points (according to rule of thumb).

collinearity problem is depicted in paired scatter plots, where each explanatory variable is plotted against each other (pairwise collinearities). From scatter plots it is evident that these pairs of explanatory variables are correlated: bad and lawyers, bad and employ, bad and pop, lawyers and employ, lawyers and pop, employ and pop. To confirm other pairwise collinearities graphical inference is not sufficient.

```{r}
crime_df = read.csv('data/expensescrime.txt', sep = '',header = TRUE)
crime_df$state = as.factor(crime_df$state)
response_vars = c('bad','crime','lawyers','employ','pop')
crime_lm = lm(expend ~ bad + crime + lawyers + employ + pop,data = crime_df)
cooks_dist = cooks.distance(crime_lm)

plot(1:51,cooks_dist,type="b", xlab='index',main='Cooks distances')
pairs(crime_df[response_vars])

round(cooks_dist[cooks_dist > 1],2)
```

### b)

By using step-up method for variable selection it was found that $expend_i = \beta_0 + \beta_1 employ_i + \beta_2 lawyers_i + e$ model is our best choice. This model reported $R^2$ value of 0.963 and by adding other explanatory variables the $R^2$ did not increase significantly (also models with three features had atleast one insignificant predictor). Therefore, third variable is not included into our linear regression. Also, we checked that chosen model's p-values for intercept, employ and lawyers were significant ($p-value < 0.05$).

The estimated $\beta_1$ and  $\beta_2$ coefficients for employ and lawyers respectively suggest that an increase of one employee in the state increases crime related expenditures by 30, while an additional lawyer costs 27 dollars.  

Trying models with one explanatory variable:
```{r}
round(summary(lm(expend ~ bad,data=crime_df))$r.squared,3)
round(summary(lm(expend ~ bad,data=crime_df))$coeff,3)
```
```{r}
round(summary(lm(expend ~ crime,data=crime_df))$r.squared,3)
round(summary(lm(expend ~ crime,data=crime_df))$coeff,3)
```

```{r}
round(summary(lm(expend ~ lawyers,data=crime_df))$r.squared,3)
round(summary(lm(expend ~ lawyers,data=crime_df))$coeff,3)
```
```{r}
round(summary(lm(expend ~ employ,data=crime_df))$r.squared,3)
round(summary(lm(expend ~ employ,data=crime_df))$coeff,3)
```
```{r}
round(summary(lm(expend ~ pop,data=crime_df))$r.squared,3)
round(summary(lm(expend ~ pop,data=crime_df))$coeff,3)
```
we choose employ as single explanatory variable, since it has the largest $R^2$ and employ is significant.

Trying models with two explanatory variables (expend ~ employ + ?):
```{r}
round(summary(lm(expend ~ employ + bad,data=crime_df))$r.squared,3)
round(summary(lm(expend ~ employ + bad,data=crime_df))$coeff,3)
```
```{r}
round(summary(lm(expend ~ employ + crime,data=crime_df))$r.squared,3)
round(summary(lm(expend ~ employ + crime,data=crime_df))$coeff,3)
```
```{r}
round(summary(lm(expend ~ employ + lawyers,data=crime_df))$r.squared,3)
round(summary(lm(expend ~ employ + lawyers,data=crime_df))$coeff,3)
```
```{r}
round(summary(lm(expend ~ employ + pop,data=crime_df))$r.squared,3)
round(summary(lm(expend ~ employ + pop,data=crime_df))$coeff,3)
```
with second iteration of step-up method, the resulting model is selected: $expend_i = \beta_0 + \beta_1 employ_i + \beta_2 lawyers_i + e$

Trying models with three explanatory variables (expend ~ employ + lawyers + ?):
```{r}
round(summary(lm(expend ~ employ + lawyers + bad,data=crime_df))$r.squared,3)
round(summary(lm(expend ~ employ + lawyers + bad ,data=crime_df))$coeff,3)
```

```{r}
round(summary(lm(expend ~ employ + lawyers + crime,data=crime_df))$r.squared,3)
round(summary(lm(expend ~ employ + lawyers + crime,data=crime_df))$coeff,3)
```

```{r}
round(summary(lm(expend ~ employ + lawyers + pop,data=crime_df))$r.squared,3)
round(summary(lm(expend ~ employ + lawyers + pop,data=crime_df))$coeff,3)
```

### c)

Our estimated 95% prediction interval for expend in our model of choice,$expend_i = \beta_0 + \beta_1 employ_i + \beta_2 lawyers_i + e$, was [-302.9307, 647.3504]. In theory, this interval could be improved by increasing sample size, however, we do not have such luxury, therefore, the only thing we could do is to increase confidence interval (for example: 98%).

```{r}
newxstate=data.frame(bad=50,crime=5000,lawyers=5000,employ=5000,pop=5000)
predict(lm(expend ~ employ + lawyers,data=crime_df), newxstate,interval="prediction",level=0.95)
```
### d)
Apply the LASSO method to choose the relevant variables (with default parameters as in the lecture and lambda=lambda.1se). (You will need to install the R-package glmnet, which is not included in the standard distribution of R.) Compare the resulting model with the model obtained in b). (Beware that in general a new run delivers a new model because of a new train set.)


For this part we refitted linear regression model from part b (recall: $expend_i = \beta_0 + \beta_1 employ_i + \beta_2 lawyers_i + e$) with training data sample that composes of 67% of original expensecrime data set. Than we estimated mean squared error (MSE) of part b model for predictions from the test data sample, which composes of 33% of original data. We want to compare b model's MSE with a new model, for which predictors are chosen with LASSO method, where $\lambda$ is derived from cross validation. As specified in the question we used most regularized $\lambda$ with errors within one standard error of the minimum. The LASSO method suggested to use lawyers and employ as predictors which is the same as our linear model from part b, where we used step up method to choose features. However, LASSO regression resulted in a model with higher MSE than model from part b when predicting was done with identical test data samples. It is also worth to address that we set the random seed of following code to 1, in order to make our results reproducible. Without set seed, each time random sampling for train and test split give different sets of data, which also results in different results for both models. 
```{r setup, include=FALSE}
library(glmnet)
```
```{r}
set.seed(1)
y=as.double(as.matrix(crime_df$expend))
x=as.matrix(crime_df[,-c(1,2)])
train=sample(1:nrow(x),0.67*nrow(x))
x.train=x[train,]; y.train=y[train]
x.test=x[-train,]; y.test=y[-train]

lm_from_b=lm(expend ~ employ + lawyers,data=crime_df, subset=train)
predict_lm_from_b=predict(lm_from_b,newdata=crime_df[-train,])
mse_lm_from_b=mean((y.test-predict_lm_from_b)^2)

lasso = glmnet(x.train,y.train,alpha=1)
cv.lasso = cv.glmnet(x.train,y.train,alpha=1,type.measure='mse')
lasso.pred=predict(lasso,s=cv.lasso$lambda.1se,newx=as.matrix(x.test))
mse.lasso=mean((y.test-lasso.pred)^2)
round(coef(lasso,s=cv.lasso$lambda.1se),4)
paste("lasso model's MSE: ",round(mse.lasso,3))
paste("part b model's MSE: ",round(mse_lm_from_b,3))
```

### Excercise 3. Titanic

#### a)
From the table we can observe that more women, regardless of age, survived compared to men. Most of the men that survived were young and under the age of 14. We can show this with a barplot, in the first barplot we can observe that most of the survivors were female and the highest amount of survivors falls in the range of 15-35. We also observe that the 1st PClasshas the most people survived, followed by 3rd and 2nd at last. We can see from logistic regression that PCLass2nd, PClass3rd, Age, Sexmale are significatant for the survival status.

```{r}
df <- read.csv("Data/titanic.txt", header=TRUE, sep="")

tot = xtabs(~PClass+Age+Sex, data=df)
tot.c=xtabs(Survived~PClass+Age+Sex, data=df)
round(tot.c/tot, 2)

tot2 = xtabs(Survived~Sex+Age, data=df)
tot_partial = xtabs(~Sex+Age, data=df)
barplot(tot2, tot_partial, xlab="age", ylab="Total Survived", legend=TRUE)

tot_pclass=xtabs(Survived~PClass, data=df)
tot_pclass_partial=xtabs(~PClass, data=df)
barplot(tot_pclass, tot_pclass_partial, xlab="Pclass", ylab="Total Survived")


# Fit a logistic regression model
titanic_model_a = glm(Survived ~ PClass + Age + Sex, data=df, family="binomial")
summary(titanic_model_a)
```

#### b)

For the interaction between Age and PClass, both Age and PClass are significant which means there exists an interaction. For Age and Sex, only Sex is significant. Indicating that Age is insignificant. The best model from these two should be Age with PClass. We can observe that the probability for survival is significant with $0.048$.

```{r}

# Age with PClass
drop1(glm(Survived ~ Age+PClass, data=df), test="Chisq")

# Age with Sex
drop1(glm(Survived ~ Age+Sex, data=df), test="Chisq")


# Age with PClass factored
df$Age = factor(df$Age)
df$PClass = factor(df$PClass)
apclass = glm(Survived ~ Age+PClass, data=df)
summary(apclass)
```


#### c)



#### d)



#### e)



### Excercise 4. Military coups

#### a)
Before performing Poisson regression on the full data set, variables pollib and numregim were transformed to factors since they have at most 4 distinct values (levels). It was also considered to transform columns oligarchy, parties and numelec to factors as well, but since they would have had significantly more levels and the interpretation of Poisson regression would be very complex, they were left as numeric variables. The only statistically significant variables in our estimated Poisson regression on full data set were: oligarchy, pollib and parties. The general Poisson regression is defined as $Y_{in} \sim Poisson(\lambda_{in}), \lambda_{in} = e^{\mu + \alpha_i + \beta X_{in}}$, where $i=1,...,I$, $n=1,...,N$. Thus, by interpreting only the coefficients of significant features we can say that the factor variable pollib increases $\lambda$ by $e^{pollib_1}=e^{-1.175}$ times, when $pollib=1$; $\lambda$ increases $e^{pollib2}=e^{-1.808}$ times, for $pollib=2$. Since default R parameterization assumes that the first level of factor is equal to 0, its coefficient is not in summary. Let $P_{in}$ denote random variable parties, then $\lambda$ would increase for every one-unit increase in $P_{in}$ by $e^{0.033}$ times. The same logic applies for variable oligarchy (lets denote it $O_{in}$), every one-unit increase in $O_{in}$, increases $\lambda$ by $e^{0.082}$ times. 
```{r}
df <- read.csv("Data/coups.txt", header=TRUE, sep=" "); set.seed(123)
df$pollib = as.factor(df$pollib); df$numregim = as.factor(df$numregim)
model_full = glm(miltcoup ~  pollib + numregim + parties + oligarchy + pctvote + popn + size + numelec, data=df, family = "poisson")
summary(model_full)
```
#### b)

Next following step down approach variable "numelec" is being eliminated due to the highest p-value. Variable represents total number of legislative and presidential elections.
```{r}
model = glm(miltcoup ~ oligarchy + pollib + parties + pctvote + popn + size + numregim, data=df, family = "poisson")
round(summary(model)$coeff,4)
```
Next we eliminate "numregim:
```{r}
model = glm(miltcoup ~ oligarchy + pollib + parties + pctvote + popn + size, data=df, family = "poisson")
round(summary(model)$coeff,4)
```
Next we eliminate "size":
```{r}
model = glm(miltcoup ~ oligarchy + pollib + parties + pctvote + popn, data=df, family = "poisson")
round(summary(model)$coeff,4)
```
Next we eliminate "popn":
```{r}
model = glm(miltcoup ~ oligarchy + pollib + parties + pctvote, data=df, family = "poisson")
round(summary(model)$coeff,4)
```
finally we eliminate "pctvote" ending up with the model were are explanatory variables are significant:
```{r}
model = glm(miltcoup ~ oligarchy + pollib + parties, data=df, family = "poisson")
round(summary(model)$coeff,4)
```
We can compare new model with eliminated variables and old model that uses variables by performing likelihood ratio test.
```{r}
anova(model_full, model, test="LRT")
```
#### c)

By using the model from b) to predict the number of coups for a hypothetical country for all the three levels of political liberalization and averages of remaining characteristics (parties and oligarchy), we can clearly observe that level of political liberalization significantly impacts results. The lower political liberalization factor, the higher predicted number of coups.

```{r}
library(ggplot2)
hypothetical_df = data.frame(pollib=c(0,1,2), oligarchy=rep(mean(df$oligarchy),3),
           parties=rep(mean(df$parties),3))
hypothetical_df$pollib = as.factor(hypothetical_df$pollib)
hypothetical_df$pred_miltcoup = predict(model, newdata=hypothetical_df, type="response")
plot(x = hypothetical_df$pollib,y=hypothetical_df$response,
     )
p = ggplot(hypothetical_df, aes(x=pollib, y=pred_miltcoup)) + geom_point()
p + xlab("pollib") + ylab("predicted miltcoup")
```
